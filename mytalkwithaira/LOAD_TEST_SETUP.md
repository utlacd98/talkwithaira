# ğŸ§ª Aira Mock Load Testing Guide

## Overview

Aira now includes a comprehensive mock load-testing mode that allows you to safely simulate 100+ concurrent users without calling real AI APIs or production databases. This is perfect for:

- âœ… Performance testing
- âœ… Stress testing
- âœ… Load capacity planning
- âœ… CI/CD pipeline testing
- âœ… Development and debugging

---

## Quick Start

### 1. Enable Mock Mode Locally

```bash
# Terminal 1: Start the dev server with mock mode
USE_MOCK_SERVICES=true LOAD_TEST_USERS=100 npm run dev
```

### 2. Run Load Simulation

```bash
# Terminal 2: Run the load test simulator
USE_MOCK_SERVICES=true LOAD_TEST_USERS=100 node scripts/simulate-load.js
```

### 3. View Results

The simulator will output:
- âœ… Total requests made
- âœ… Success/failure rates
- âœ… Requests per second
- âœ… Duration
- âœ… Any errors encountered

---

## Environment Variables

### Required

| Variable | Default | Description |
|----------|---------|-------------|
| `USE_MOCK_SERVICES` | `false` | Set to `true` to enable mock mode |
| `LOAD_TEST_USERS` | `100` | Number of concurrent users to simulate |

### Optional (for simulator script)

| Variable | Default | Description |
|----------|---------|-------------|
| `BASE_URL` | `https://v0-aira-web-app.vercel.app` | API base URL |
| `REQUESTS_PER_USER` | `10` | Requests each user makes |
| `DELAY_BETWEEN_REQUESTS` | `500` | Delay between requests (ms) |

---

## Usage Examples

### Example 1: Local Development (50 users)

```bash
USE_MOCK_SERVICES=true LOAD_TEST_USERS=50 npm run dev
```

Then in another terminal:

```bash
USE_MOCK_SERVICES=true LOAD_TEST_USERS=50 node scripts/simulate-load.js
```

### Example 2: Production Simulation (100 users)

```bash
BASE_URL=https://v0-aira-web-app.vercel.app \
USE_MOCK_SERVICES=true \
LOAD_TEST_USERS=100 \
node scripts/simulate-load.js
```

### Example 3: Heavy Load Test (500 users, 20 requests each)

```bash
USE_MOCK_SERVICES=true \
LOAD_TEST_USERS=500 \
REQUESTS_PER_USER=20 \
DELAY_BETWEEN_REQUESTS=100 \
node scripts/simulate-load.js
```

### Example 4: Stress Test (1000 users, rapid requests)

```bash
USE_MOCK_SERVICES=true \
LOAD_TEST_USERS=1000 \
REQUESTS_PER_USER=5 \
DELAY_BETWEEN_REQUESTS=50 \
node scripts/simulate-load.js
```

---

## What Gets Mocked

### âœ… AI Responses
- No OpenAI API calls
- No token usage
- Realistic response times (50-150ms)
- Varied mock responses

### âœ… Redis/Database
- In-memory storage
- No external connections
- Instant operations
- Realistic delays (20-300ms)

### âœ… Chat Saves
- Mock Vercel KV responses
- In-memory fallback
- No file system writes

### âœ… User Stats
- Mock dashboard data
- Realistic stat generation
- Session tracking

---

## API Endpoints

### GET /api/test/load

Returns current load test status:

```bash
curl http://localhost:3000/api/test/load
```

Response:
```json
{
  "status": "active",
  "loadUsers": 100,
  "activeSessions": 42,
  "sessionDetails": [
    {
      "userId": "user-0",
      "sessionId": "session-1729...",
      "messageCount": 5,
      "lastActivity": "2025-10-26T18:00:00.000Z"
    }
  ],
  "timestamp": "2025-10-26T18:00:00.000Z",
  "mock": true
}
```

### POST /api/test/load

Clear all mock sessions:

```bash
curl -X POST http://localhost:3000/api/test/load \
  -H "Content-Type: application/json" \
  -d '{"action":"clear"}'
```

---

## Mock Endpoints

When `USE_MOCK_SERVICES=true`, these endpoints return mock data:

| Endpoint | Mock Behavior |
|----------|---------------|
| `POST /api/chat` | Returns mock AI response (50-150ms) |
| `GET /api/dashboard` | Returns mock user stats |
| `POST /api/chat/save` | Returns mock save confirmation |
| `GET /api/test/load` | Returns load test status |

---

## Console Output

### Startup Message

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ§ª MOCK LOAD TEST MODE ACTIVE                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Simulated Users: 100                                      â•‘
â•‘  AI Calls: MOCKED (no token cost)                          â•‘
â•‘  Redis: MOCKED (in-memory)                                 â•‘
â•‘  Database: MOCKED (in-memory)                              â•‘
â•‘                                                            â•‘
â•‘  âš ï¸  This is for testing only. Do not use in production.   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Simulator Output

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“Š LOAD TEST RESULTS                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Total Requests:        1000                               â•‘
â•‘  Successful:            998                                â•‘
â•‘  Failed:                2                                  â•‘
â•‘  Success Rate:          99.80%                             â•‘
â•‘  Duration:              45.23s                             â•‘
â•‘  Requests/Second:       22.11                              â•‘
â•‘  Simulated Users:       100                                â•‘
â•‘  Requests per User:     10                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Performance Metrics

### Expected Performance (Local)

- **100 users**: ~20-30 req/s
- **500 users**: ~50-80 req/s
- **1000 users**: ~100-150 req/s

### Expected Performance (Vercel)

- **100 users**: ~15-25 req/s
- **500 users**: ~40-60 req/s
- **1000 users**: ~80-120 req/s

---

## Troubleshooting

### Issue: "Mock mode is not enabled"

**Solution**: Make sure `USE_MOCK_SERVICES=true` is set:

```bash
USE_MOCK_SERVICES=true node scripts/simulate-load.js
```

### Issue: Connection refused

**Solution**: Make sure the dev server is running:

```bash
# Terminal 1
npm run dev

# Terminal 2
node scripts/simulate-load.js
```

### Issue: High failure rate

**Solution**: Reduce concurrent users or increase delays:

```bash
USE_MOCK_SERVICES=true \
LOAD_TEST_USERS=50 \
DELAY_BETWEEN_REQUESTS=1000 \
node scripts/simulate-load.js
```

---

## Best Practices

1. **Start Small**: Begin with 50 users, then increase
2. **Monitor Logs**: Watch console output for errors
3. **Test Locally First**: Run on localhost before Vercel
4. **Vary Requests**: Mix different endpoints
5. **Realistic Delays**: Use realistic request intervals
6. **Clear Sessions**: Use POST /api/test/load to reset

---

## Files Added

- âœ… `/lib/mock-services.ts` - Mock service implementations
- âœ… `/app/api/test/load/route.ts` - Load test endpoint
- âœ… `/scripts/simulate-load.js` - Load simulator script
- âœ… `/LOAD_TEST_SETUP.md` - This documentation

---

## Next Steps

1. âœ… Enable mock mode: `USE_MOCK_SERVICES=true`
2. âœ… Run simulator: `node scripts/simulate-load.js`
3. âœ… Monitor performance
4. âœ… Adjust load as needed
5. âœ… Analyze results

---

**Status**: âœ… Ready for Load Testing
**Last Updated**: October 26, 2025

